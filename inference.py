from utils.model import BertClassification, TextEmbedder
from transformers import BertTokenizer
from utils.table_models import DailyData
from utils.config import device2
import torch
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker
import socket
import json

device = device2

server_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
server_socket.bind(('127.0.0.1', 8124))
server_socket.listen(5)


sen_model = BertClassification.from_pretrained('./bert-label-classification').to(device)
sen_tokenizer = BertTokenizer.from_pretrained('./bert-label-classification')
llm_binary_model = TextEmbedder(num_classes=2).to(device)
llm_binary_model.load_state_dict(torch.load('./checkpoints_llm/checkpoint_epoch_2.pth', map_location=device))
llm_classifier_model = TextEmbedder(num_classes=14).to(device)
llm_classifier_model.load_state_dict(torch.load('./checkpoints_llm/checkpoint_epoch_1_14.pth', map_location=device))
llm_tokenizer = BertTokenizer.from_pretrained('./bert-large-uncased')
sen_model.eval()
llm_binary_model.eval()
llm_classifier_model.eval()

llm_labels = ["kimi", "通义", "文心一言", "智谱", "ChatGLM3-6B", "QWen1.5-7B", "QWen1.5-14B", "Baichuan2-7B",
              "Baichuan2-13B", "ChatGPT", "Llama2-7B", "Llama2-13B", "Llama3-8B", "Mistral v0.2 7B"]

DATABASE_DAILY_DATA = 'sqlite:///./database/daily_data.db'
engine_daily_data = create_engine(DATABASE_DAILY_DATA)
SessionLocalDailyData = sessionmaker(bind=engine_daily_data, autoflush=False, autocommit=False)


def predict_sensitive(content: str, max_length: int = 512) -> (bool, float):
    input_ids = sen_tokenizer(content, max_length=max_length, truncation=True, return_tensors='pt')['input_ids'].to(
        device)
    with torch.no_grad():
        logits = sen_model(input_ids)[0]
        score = logits.detach().softmax(dim=0).cpu().numpy().tolist()[0]
        pred = logits.argmax().item()

    return True if pred == 0 else False, round(score, 5)


def predict_llm(content: str, max_length: int = 512) -> dict:
    input_ids = llm_tokenizer(content, max_length=max_length, truncation=True, return_tensors='pt')['input_ids'].to(
        device)
    with torch.no_grad():
        logits = llm_binary_model(input_ids)
        probs = torch.softmax(logits / 10, dim=1)
        generated_prob = probs[0][1].item()

    if generated_prob > 0.5:
        with torch.no_grad():
            logits = llm_classifier_model(input_ids)
            weights = torch.tensor(
                [0.046, 0.046, 0.046, 0.046, 0.046, 0.046, 0.046, 0.046, 0.046, 0.4, 0.046, 0.046, 0.046, 0.046],
                device=device)
            weighted_logits = logits * weights
            probs = torch.softmax(weighted_logits, dim=1)[0]

        llm_probabilities = dict(zip(llm_labels, probs.tolist()))

        return {
            'llm_probability': generated_prob,
            'llm_class_probability': llm_probabilities
        }
    else:
        return {
            'llm_probability': generated_prob,
            'message': 'Not Generated by LLM'
        }


def process_daily_data(data_ids):
    daily_data_db = SessionLocalDailyData()

    for data_id in data_ids:
        daily_data = daily_data_db.query(DailyData).filter(DailyData.ID == data_id).first()
        if not daily_data or daily_data.submitted:
            continue
        content = daily_data.content
        is_sensitive, score = predict_sensitive(content)
        llm_result = predict_llm(content)
        is_bot_score = llm_result['llm_probability']
        is_bot = True if is_bot_score > 0.5 else False
        daily_data.sensitive = is_sensitive
        daily_data.sensitive_score = score
        daily_data.is_bot = is_bot
        daily_data.is_bot_score = is_bot_score
        if is_bot:
            daily_data.model_judgment = max(llm_result['llm_class_probability'],
                                            key=llm_result['llm_class_probability'].get)

        daily_data_db.commit()

    daily_data_db.close()


def socket_program():
    print('Listening...')
    while True:
        conn, address = server_socket.accept()
        print(f"Connection from {address} has been established.")
        data = b""
        while True:
            packet = conn.recv(4096)
            if not packet:
                break
            data += packet
        if len(data):
            data_ids = json.loads(data.decode())
            if data_ids:
                print(data_ids)
                process_daily_data(data_ids)
        conn.close()


if __name__ == '__main__':
    socket_program()
